\documentclass{article}
\begin{document}
	
Mechanics of the brain

$\linebreak$
let $n_x$ $\in$ N $\mid$ $x$ is the index of the neuron in the finite set N where N is the set of all neurons in the system of concern.

$\linebreak$
let B be a graph $\mid$ N is the set of nodes and C is the set of edges between nodes $n_x$ and $n_y$

$\linebreak$
let $g$ be the "thought algorithm" (a sequence of transition functions) for the brain. $B'$ is the result of the brain having one "thought." $g'$ is the next "thought" the brain is going to have. "Thoughts" can create neurons and connections between them.

$\linebreak$
\(\forall g(B) \in\) the set of all "thoughts" on a given brain $B$ $\exists$ a brain $B'$ and an algorithm \(g' \mid g(B) = [B', g']\)

$\linebreak$
Every application of the "thought algorithm" $g$ moves the brain from the state $[B,g]$ to $[B',g']$.


$\linebreak$
Let us concern ourselves first, and only for the moment, with how this "thought algorithm" produces the next state of the brain. We could 


$\linebreak$
Consider the deterministic progression of all "thoughts" ($g$) for a given brain ($B$ : really a single state of a brain, leading to the next state of that brain $B'$), and consider that part of the state of this system is the next action to be taken on this system ($g'$ : which would be the next "thought" algorithm to be executed.)

$\linebreak$
The description of the traversal of the graph B is the language of the brain. "Zero goes to one, and two." Is one sentence. Consider the following "paragraph":
\[0:n_0 \rightarrow [n_1, n_2]\]
\[1:n_1 \rightarrow [n_{40}, n_{2}, n_{33}], n_2 \rightarrow [n_3, n_7]\]
\[2:n_{40} \rightarrow [n_1],n_{2} \rightarrow [], n_{33} \rightarrow [], n_3 \rightarrow [n_2], n_7 \rightarrow [] \]
\[3:n_1 \rightarrow [], n_2 \rightarrow [] \]
This gives us a declarative, and, clearly, context sensitive, language for thoughts. Consider the alternative paragraph where sentence 3 follows sentence 0:
\[0:n_0 \rightarrow [n_1, n_2]\]
\[3:n_1 \rightarrow [], n_2 \rightarrow [] \]
In practice, we can omit the final step, where all neurons $n_x$ goto the empty list. This is important for a clean composition of "thoughts." We would also emit any transition from $n_x$ to the empty list.

$\linebreak$

\[f_x(B,g) = f_{x+1}(B',g') \mid g(B) = [B', g']\]

$\linebreak$
To this point, we have created a specialized, and simplified, model of "thoughts." My intuition is that this is all that is required for thoughts to exist. However, we wish to be as exhaustive as possible for our theory of "thoughts." To be sure to capture as many of the quantifiable elements that may impact the emergence of consciousness. The weights on the edges of the graph B would be the "strength" of the connections between neurons or the distance between neurons and, hense, the time it takes to traverse the synapse. I purpose we capture both weights, as a pair of weights on the edges. For the purposes of computation, as we would wish to track the timing from one synapse to the next. I would argue that this would make a mess of an otherwise elegant computation, however, this is how the brain actually works, so it is relevant to capture this feature. It is, again, my intuition, that this is not required for "consciousness."

$\linebreak$
Additionally, we could add an additional dimension of complexity, a layered graph. Essentially a list of graphs, each representing one neurotransmitter. So an array of graphs.

$\linebreak$
A = [E,S,D] $\mid$ E,S,D are B graphs, E for norepinephrine, S for serotonin, and D for dopamine

$\linebreak$
Or, optionally/analogously/inversely, the length of time is would take to traverse the synapse. In other words: there are several weights one could apply to create a full mathematical model, applying a "timbre" to the "thoughts" produced.

$\linebreak$

Language of the brain

$\linebreak$
The transitions of the brain from [B,g] to [B',g'] are not the inputs or output of the brain. In the instance of a human being, our inputs are our senses and our outputs are our actions in the world. Our thoughts are what occur in between. It is my belief that the functions g$_x$ are, in fact, "thoughts."



One would like to map a word to each thought in g$_x$, however, there are an infinite number of such functions, as the number of neurons and connections between them could be constantly growing, and the number of steps in each transition is undefined 

I would rather assume that such a mapping would be a novel, and that the words are the traversals. A single human thought would require an enormous text. In fact, our inputs, our senses, are translated, by our brains, into an experience. An experience is a sequence of thoughts. Because we have a medium to "remember" our thoughts, we can have an "experience." If one can have an experience, I would assert that, one is conscious. Consciousness is this "experiencing" of thoughts. The mere simulation of the mechanics of thoughts (the traversal of the graph B) may, in fact, give rise to thoughts. These thoughts would be ephemeral, having no substance underneath by which they are preserved so as to allow for an "experience" to occur. Throughout the universe there are countless phenomenon which simulate or approximate the traversal of the graph B. However, only a small portion of these are fortunate subjects possessing a medium which stores their existence. The human brain does so by reinforcing connections between neurons and forming new ones. Perhaps there are other such instances of mediums by which thoughts become consciousness. Certainly one can imagine doing so virtually. By simply simulating the mechanics of a human brain. Saving the state of the system. But there are countless other ways we could achieve this storage of thoughts digitally. Would all of them provide consciousness? Different varieties of consciousness perhaps? What of the language of happiness, joy, grief, and sorrow.

$\linebreak$

Abstractions

$\linebreak$
Can we find meaningful abstractions around the "thought algorithm" $g$? Are there mappings such that 
\[\forall x \exists h(g_x) \in T\]
\[h(g_x) = A Thought Like Hello or Natural Language Word\] 
\[T = Thoughts Like Hello Goodbye HowAreYou\]

$\linebreak$

Operations of $g$

$\linebreak$
Composition: $g \circ k$:
$\linebreak$
\(g = \{\) 
\(0: n_10 \rightarrow [n_11, n_6] \)
\(1: n_6 \rightarrow [n_8], n_11 \rightarrow [n_12, n_15] \linebreak
(omit)2: n_8 \rightarrow [], n_12 \rightarrow [], n_15 \rightarrow [] \linebreak
\} \linebreak
k = \{ \linebreak
0: n_8 \rightarrow [n_10, n_12] \linebreak
\} \linebreak
g \circ k = \{ \linebreak
0: n_10 \rightarrow [n_11, n_6] \linebreak
1: n_6 \rightarrow [n_8], n_11 \rightarrow [n_12, n_15] \linebreak
2: n_8 \rightarrow [n_10, n_12] \linebreak
\} \linebreak
k \circ g = \{ \linebreak
0: n_8 \rightarrow [n_10, n_12] \linebreak
1: n_10 \rightarrow [n_11, n_6] \linebreak
2: n_6 \rightarrow [n_8], n_11 \rightarrow [n_12, n_15] \linebreak
\} \linebreak
\)


$\linebreak$
\[x!  = x * (x-1) * (x-2) * ... * 1\]
\[x^y = x * (x+y^1-y^1) * (x+y^2-y^2) *... * (x+y^n-y^n)\]
\[x(x-y)(x-(y+1))(x-(y+2)) ... (x-(y+n))\]

$\linebreak$

Rough assertion that factorial and exponetial problems are of equivelent complexity (NP obviously), and that no additional complexity class above the other exists for either growth function
$\linebreak$

here's what I'm thinking:
we find any arbitrary intercept for x and some y.
There exists some intercept for every factorial number and every expontial number of x
The representations are different... but any NP problem of this complexity is of the SAME complexity. That is to say that ! and exp problems are the same complexity, not some greater complexity class. I think... Idk... Yeah. Same complexity class. Does that make sense??? Idk.
I'm just saying 
There is a subset of NP... for optimization problems.. QP, right? There isn't some superset for ! or exp. I don't think.



An afterthought:
There are only two things in the entire universe that you can be assured of. I think therefor I am: you know that YOU exist. That YOU are thinking and therefor you are a conscious being. AND you know that one plus one equals two. And you can construct an axiomatic system of mathematics (an infinite number of axiomatic systems of mathematics) that can be made universally equivalent. In other words. One plus one equals two in my mind, and one plus one equals two in your mind. For all minds, universally. And, if you were God, this would be important to you. Because it forms the basis for communication between consciousnesses. And, if you were the intelligent designer of the universe. Perhaps this would be the linchpin of consciousness in general. That one plus one MUST equal two universally, lest all consciousness be splintered irreproachably. Disjoint without any hope of reconciliation. However, a language between consciousnesses can exist, with only the existence of consciousness and the mathematics shared between them.
\end{document}



